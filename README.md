# GLaSS-SS: Group-Laplacian Structured Shrinkage with Stability Selection

[![R](https://img.shields.io/badge/R-276DC3?style=flat&logo=r&logoColor=white)](https://www.r-project.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

ê³ ì°¨ì› ë°ì´í„°ì—ì„œ ê·¸ë£¹ êµ¬ì¡°ì™€ ìƒê´€ê´€ê³„ë¥¼ ë™ì‹œì— ê³ ë ¤í•œ ì•ˆì •ì ì¸ ë³€ìˆ˜ ì„ íƒ ë°©ë²•

## ğŸ“‹ ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [ì£¼ìš” ê¸°ëŠ¥](#ì£¼ìš”-ê¸°ëŠ¥)
- [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
- [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
- [íŒŒì¼ êµ¬ì¡°](#íŒŒì¼-êµ¬ì¡°)
- [ë°©ë²•ë¡ ](#ë°©ë²•ë¡ )
- [ì„±ëŠ¥ ë¹„êµ](#ì„±ëŠ¥-ë¹„êµ)
- [ì‹œë®¬ë ˆì´ì…˜ ì—°êµ¬](#ì‹œë®¬ë ˆì´ì…˜-ì—°êµ¬)
- [ì°¸ê³  ë¬¸í—Œ](#ì°¸ê³ -ë¬¸í—Œ)

## ê°œìš”

GLaSS-SSëŠ” ê³ ì°¨ì› ìƒë¬¼í•™ì  ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ê°•ë ¥í•œ ë³€ìˆ˜ ì„ íƒ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë³€ìˆ˜ ê°„ **ê·¸ë£¹ êµ¬ì¡°**ì™€ **ìƒê´€ê´€ê³„**ë¥¼ ë™ì‹œì— í™œìš©í•˜ì—¬ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ì•ˆì •ì ì´ê³  í•´ì„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•

- **ì ì‘ì  í˜ë„í‹° ìµœì í™”**: Group Lassoì™€ Laplacian ì •ê·œí™”ë¥¼ í˜¼í•©
- **ì•ˆì •ì„± ì„ íƒ**: Stability Selectionìœ¼ë¡œ False Discovery ì œì–´
- **ë³‘ë ¬ ì²˜ë¦¬**: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ íš¨ìœ¨ì ì¸ ì—°ì‚°
- **ìœ ì—°í•œ ê·¸ë£¹ êµ¬ì¡°**: ë‹¤ì–‘í•œ ê·¸ë£¹ ì •ì˜ ì§€ì›

## ì£¼ìš” ê¸°ëŠ¥

### 1. ê·¸ë˜í”„ êµ¬ì¡° í•™ìŠµ
```r
# GLASSOë¡œ ìµœì  ì¸ì ‘ í–‰ë ¬ ìƒì„±
adj_matrix <- create_optimal_adjacency_glasso(X)

# ìƒê´€ê´€ê³„ ê¸°ë°˜ ë¼í”Œë¼ì‹œì•ˆ í–‰ë ¬ ìƒì„±
L <- create_laplacian_matrix(X)
```

### 2. ì ì‘ì  í˜ë„í‹° ìµœì í™”
```r
# GLaSS ëª¨ë¸ ì í•©
result <- fit_adaptive_penalty_optim_noCV(
  X = X_train,
  y = y_train,
  L_sparse = L,
  groups = groups,
  alpha_seq = seq(0, 1, 0.25),  # Lasso-Laplacian í˜¼í•© ë¹„ìœ¨
  nlambda = 10
)
```

### 3. ì•ˆì •ì„± ì„ íƒ
```r
# ë³‘ë ¬ ì•ˆì •ì„± ì„ íƒ
stabsel_result <- my_stabsel_parallel(
  x = X_train,
  y = y_train,
  fitfun = my_adaptive_fitfun,
  args.fitfun = list(groups = groups, L_sparse = L),
  cutoff = 0.6,
  pfer_values = c(1, 5, 10),
  B = 50,
  mc.cores = 10
)
```

## ì„¤ì¹˜ ë°©ë²•

### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```r
# CRAN íŒ¨í‚¤ì§€
install.packages(c(
  "Matrix", "Rcpp", "glmnet", "grpreg",
  "huge", "stabs", "parallel",
  "tidyverse", "mvtnorm", "corrplot",
  "pROC", "randomForest", "ggplot2", "gridExtra"
))
```

### GLaSS-SS ë‹¤ìš´ë¡œë“œ

```bash
git clone https://github.com/yonghankwon0/GLaSS-SS.git
cd GLaSS-SS
```

## ë¹ ë¥¸ ì‹œì‘

### ê°„ë‹¨í•œ ì˜ˆì œ ì‹¤í–‰

```r
# ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
source("example_quick_start.R")
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤:
1. **ê¸°ë³¸ ì‚¬ìš©ë²•**: ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ GLaSS-SS ì‹¤í–‰
2. **ë°©ë²• ë¹„êµ**: Lasso, Elastic Netê³¼ ì„±ëŠ¥ ë¹„êµ
3. **ì‹œê°í™”**: ì„ íƒ í™•ë¥  ë¶„í¬ í™•ì¸

### ì§ì ‘ ì‹¤í–‰í•˜ê¸°

```r
# 1. ë©”ì„œë“œ ë¡œë“œ
source("glass_ss_methods.R")

# 2. ë°ì´í„° ìƒì„±
set.seed(123)
data <- generate_group_data(n = 100, snr = 1, half = 0)

# 3. í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
train_idx <- sample(1:nrow(data$X), 70)
X_train <- data$X[train_idx, ]
y_train <- data$y[train_idx]

# 4. ê·¸ë£¹ ë° ê·¸ë˜í”„ êµ¬ì¡° ì •ì˜
groups <- rep(1:3, each = 40)
L <- create_laplacian_matrix(X_train)

# 5. GLaSS-SS ì‹¤í–‰
result <- my_stabsel_parallel(
  x = X_train,
  y = y_train,
  fitfun = my_adaptive_fitfun,
  args.fitfun = list(
    groups = groups,
    L_sparse = L,
    alpha_seq = seq(0, 1, 0.25),
    nlambda = 10
  ),
  cutoff = 0.6,
  pfer_values = c(5),
  sampling.type = "SS",
  B = 20,
  mc.cores = 4
)

# 6. ê²°ê³¼ í™•ì¸
selected_vars <- result[["5"]]$selected
cat("ì„ íƒëœ ë³€ìˆ˜:", length(selected_vars), "ê°œ\n")
```

## íŒŒì¼ êµ¬ì¡°

```
GLaSS-SS/
â”œâ”€â”€ glass_ss_methods.R          # í•µì‹¬ ë©”ì„œë“œ êµ¬í˜„
â”‚   â”œâ”€â”€ ê·¸ë˜í”„ êµ¬ì¡° í•¨ìˆ˜
â”‚   â”œâ”€â”€ GLaSS ìµœì í™” ì•Œê³ ë¦¬ì¦˜
â”‚   â”œâ”€â”€ ì•ˆì •ì„± ì„ íƒ í†µí•©
â”‚   â””â”€â”€ ê¸°ì¤€ ë°©ë²• (Lasso, Elastic Net, Group Lasso)
â”‚
â”œâ”€â”€ simulation_study.R          # ì‹œë®¬ë ˆì´ì…˜ ë° ì„±ëŠ¥ í‰ê°€
â”‚   â”œâ”€â”€ ë°ì´í„° ìƒì„± í•¨ìˆ˜
â”‚   â”œâ”€â”€ ì•ˆì •ì„± ë©”íŠ¸ë¦­ ê³„ì‚°
â”‚   â”œâ”€â”€ ì„±ëŠ¥ í‰ê°€ í”„ë ˆì„ì›Œí¬
â”‚   â””â”€â”€ ì‹œê°í™” í•¨ìˆ˜
â”‚
â”œâ”€â”€ example_quick_start.R       # ë¹ ë¥¸ ì‹œì‘ ì˜ˆì œ
â”‚   â”œâ”€â”€ ê¸°ë³¸ ì‚¬ìš©ë²•
â”‚   â”œâ”€â”€ ë°©ë²• ë¹„êµ
â”‚   â””â”€â”€ ê²°ê³¼ ì‹œê°í™”
â”‚
â””â”€â”€ README.md                   # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## ë°©ë²•ë¡ 

### GLaSS-SS ëª©ì  í•¨ìˆ˜

GLaSS-SSëŠ” ë‹¤ìŒ ëª©ì  í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤:

```
minimize: L(Î²) + Î»Â·Î±Â·Î£âˆš(|G_j|)||Î²_G_j||_2 + Î»Â·(1-Î±)Â·Î²^T L Î²
```

ì—¬ê¸°ì„œ:
- `L(Î²)`: ë¡œì§€ìŠ¤í‹± ì†ì‹¤ í•¨ìˆ˜
- `Î± âˆˆ [0,1]`: Group Lassoì™€ Laplacian ì •ê·œí™”ì˜ í˜¼í•© ë¹„ìœ¨
- `G_j`: jë²ˆì§¸ ê·¸ë£¹ì˜ ë³€ìˆ˜ ì¸ë±ìŠ¤
- `L`: ë¼í”Œë¼ì‹œì•ˆ í–‰ë ¬ (ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì¸ì½”ë”©)

### ìµœì í™” ì•Œê³ ë¦¬ì¦˜

**Generalized Forward-Backward Splitting (GFBS)** ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©:

1. **ì´ˆê¸°í™”**: Î²â° = 0, ë‘ ê°œì˜ ë³´ì¡° ë³€ìˆ˜ z_gâ°, z_lâ° ì„¤ì •
2. **ë°˜ë³µ**:
   - Gradient step: ë¡œì§€ìŠ¤í‹± ì†ì‹¤ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
   - Proximal operator (Group Lasso): ê·¸ë£¹ë³„ soft-thresholding
   - Proximal operator (Laplacian): 2ì°¨ ì •ê·œí™” í•´ê²°
   - ë³€ìˆ˜ ì—…ë°ì´íŠ¸ ë° ìˆ˜ë ´ í™•ì¸

### ì•ˆì •ì„± ì„ íƒ

**Stability Selection** í”„ë ˆì„ì›Œí¬ë¡œ False Discovery ì œì–´:

1. **ì„œë¸Œìƒ˜í”Œë§**: ë°ì´í„°ë¥¼ Bë²ˆ ë°˜ë³µ ì„œë¸Œìƒ˜í”Œë§ (ë³´í†µ B=50-100)
2. **ë³€ìˆ˜ ì„ íƒ**: ê° ì„œë¸Œìƒ˜í”Œì—ì„œ GLaSS ì‹¤í–‰
3. **ì„ íƒ í™•ë¥  ê³„ì‚°**: P_hat(j) = (ë³€ìˆ˜ jê°€ ì„ íƒëœ íšŸìˆ˜) / B
4. **ìµœì¢… ì„ íƒ**: P_hat(j) > cutoffì¸ ë³€ìˆ˜ë§Œ ì„ íƒ (ë³´í†µ cutoff=0.6)

**Per-Family Error Rate (PFER) ì œì–´**:
```
E[FP] â‰¤ (qÂ²)/(Ï€cutoff - 0.5) â‰¤ PFER
```

## ì„±ëŠ¥ ë¹„êµ

### ë¹„êµ ëŒ€ìƒ ë°©ë²•

1. **Lasso + Stability Selection**: ê¸°ë³¸ L1 ì •ê·œí™”
2. **Elastic Net + Stability Selection**: L1 + L2 í˜¼í•©
3. **Group Lasso + Stability Selection**: ê·¸ë£¹ êµ¬ì¡°ë§Œ í™œìš©
4. **Elastic Net (CV)**: Cross-validation ê¸°ë°˜
5. **Group Lasso (CV)**: Cross-validation ê¸°ë°˜

### í‰ê°€ ì§€í‘œ

- **True Positive Rate (TPR)**: ì‹¤ì œ ì‹ í˜¸ ë³€ìˆ˜ì˜ íƒì§€ìœ¨
- **Positive Predictive Value (PPV)**: ì„ íƒëœ ë³€ìˆ˜ ì¤‘ ì‹¤ì œ ì‹ í˜¸ ë¹„ìœ¨
- **F1 Score**: TPRê³¼ PPVì˜ ì¡°í™” í‰ê· 
- **AUC**: Random Forest ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥
- **Nogueira Stability**: ì„ íƒì˜ ì•ˆì •ì„± ì¸¡ì •
- **Jaccard Stability**: ë°˜ë³µ ê°„ ì„ íƒ ì¼ê´€ì„±

## ì‹œë®¬ë ˆì´ì…˜ ì—°êµ¬

### ì‹œë®¬ë ˆì´ì…˜ ì‹œë‚˜ë¦¬ì˜¤

```r
# simulation_study.R ì‹¤í–‰
source("simulation_study.R")
```

í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
- **ìƒ˜í”Œ í¬ê¸°**: n âˆˆ {60, 120}
- **SNR**: Signal-to-Noise Ratio âˆˆ {1}
- **ì‹ í˜¸ íŒ¨í„´**:
  - Block signal (3 groups)
  - Sparse signal (30% active in groups)
- **ê·¸ë£¹ êµ¬ì¡°**:
  - Well-specified: 6 groups Ã— 20 variables
  - Misspecified: 3 groups Ã— 40 variables
  - Fine-grained: 12 groups Ã— 10 variables

### ê²°ê³¼ ì¶œë ¥

ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹œ ìƒì„±ë˜ëŠ” íŒŒì¼:
```
simulation_results_YYYY-MM-DD_HH-MM-SS/
â”œâ”€â”€ *.txt                       # ìƒì„¸ ê²°ê³¼ ë¡œê·¸
â”œâ”€â”€ sim_result_*.rds            # R ê°ì²´ ì €ì¥
â””â”€â”€ all_plots_*.pdf             # ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„
```

## ì°¸ê³  ë¬¸í—Œ

### ì´ë¡ ì  ë°°ê²½

1. **Stability Selection**
   Meinshausen, N., & BÃ¼hlmann, P. (2010). Stability selection. *Journal of the Royal Statistical Society: Series B*, 72(4), 417-473.

2. **Group Lasso**
   Yuan, M., & Lin, Y. (2006). Model selection and estimation in regression with grouped variables. *Journal of the Royal Statistical Society: Series B*, 68(1), 49-67.

3. **Graph-Guided Fused Lasso**
   Kim, S., & Xing, E. P. (2009). Statistical estimation of correlated genome associations to a quantitative trait network. *PLoS Genetics*, 5(8), e1000587.

4. **Forward-Backward Splitting**
   Combettes, P. L., & Pesquet, J. C. (2011). Proximal splitting methods in signal processing. In *Fixed-point algorithms for inverse problems in science and engineering* (pp. 185-212). Springer.

### ê´€ë ¨ íŒ¨í‚¤ì§€

- **stabs**: Stability selection implementation
- **glmnet**: Lasso and Elastic Net
- **grpreg**: Group regularization
- **huge**: High-dimensional graph estimation

## ë¬¸ì˜ ë° ê¸°ì—¬

ì´ìŠˆ ë° ì œì•ˆì‚¬í•­ì€ [GitHub Issues](https://github.com/yonghankwon0/GLaSS-SS/issues)ì— ë“±ë¡í•´ì£¼ì„¸ìš”.

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.
